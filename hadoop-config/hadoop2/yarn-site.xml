<?xml version="1.0"?>
<configuration>
	<!-- Rm Begin -->
	<property>
		<name>yarn.resourcemanager.ha.enabled</name>
		<value>true</value>
	</property>
	<property>
		<name>yarn.resourcemanager.ha.automatic-failover.embedded</name>
		<value>true</value>
	</property>
	<property>
		<name>yarn.resourcemanager.cluster-id</name>
		<value>pseudo-yarn-rm-cluster</value>
	</property>
	<property>
		<name>yarn.resourcemanager.ha.rm-ids</name>
		<value>rm1,rm2</value>
	</property>
	<property>
		<name>yarn.resourcemanager.recovery.enabled</name>
		<value>true</value>
		<description>默认值为false，也就是说resourcemanager挂了相应的正在运行的任务在rm恢复后不能重新启动</description>
	</property>
	<property>
		<name>yarn.resourcemanager.store.class</name>
		<value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>
		<description>此版本的rmstate信息存放主要有两种，一种是FileSystemRMStateStore,另一种是MemoryRMStateStore，还有一>种目前较为主流的是zkstore，正在测试中</description>
	</property>
	<property>
		<name>yarn.resourcemanager.zk-address</name>
		<value>nn1.hadoop:2181,nn2.hadoop:2181,s1.hadoop:2181</value>
	</property>
	<property>
		<name>yarn.resourcemanager.zk.state-store.address</name>
		<value>nn1.hadoop:2181,nn2.hadoop:2181,s1.hadoop:2181</value>
	</property>
	<property>
		<name>yarn.app.mapreduce.am.scheduler.connection.wait.interval-ms</name>
		<value>5000</value>
	</property>
	<!-- RM1 configs -->
	<property>
		<name>yarn.resourcemanager.address.rm1</name>
		<value>nn1.hadoop:8032</value>
		<description>ResourceManager 对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等</description>
	</property>
	<property>
		<name>yarn.resourcemanager.scheduler.address.rm1</name>
		<value>nn1.hadoop:8030</value>
		<description>ResourceManager 对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资>源等。</description>
	</property>
	<property>
		<name>yarn.resourcemanager.webapp.https.address.rm1</name>
		<value>nn1.hadoop:8089</value>
	</property>
	<property>
		<name>yarn.resourcemanager.webapp.address.rm1</name>
		<value>nn1.hadoop:8088</value>
		<description>ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息。</description>
	</property>
	<property>
		<name>yarn.resourcemanager.resource-tracker.address.rm1</name>
		<value>nn1.hadoop:8031</value>
		<description>ResourceManager 对NodeManager暴露的地址.。NodeManager通过该地址向RM汇报心跳，领取任务等。</description>
	</property>
	<property>
		<name>yarn.resourcemanager.admin.address.rm1</name>
		<value>nn1.hadoop:8033</value>
		<description>ResourceManager 对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等</description>
	</property>
	
	<!-- RM2 configs -->
	<property>
		<name>yarn.resourcemanager.address.rm2</name>
		<value>nn2.hadoop:8032</value>
		<description>ResourceManager 对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等</description>
	</property>
	<property>
		<name>yarn.resourcemanager.scheduler.address.rm2</name>
		<value>nn2.hadoop:8030</value>
		<description>ResourceManager 对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资>源等。</description>
	</property>
	<property>
		<name>yarn.resourcemanager.webapp.https.address.rm2</name>
		<value>nn2.hadoop:8089</value>
	</property>
	<property>
		<name>yarn.resourcemanager.webapp.address.rm2</name>
		<value>nn2.hadoop:8088</value>
		<description>ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息。</description>
	</property>
	<property>
		<name>yarn.resourcemanager.resource-tracker.address.rm2</name>
		<value>nn2.hadoop:8031</value>
		<description>ResourceManager 对NodeManager暴露的地址.。NodeManager通过该地址向RM汇报心跳，领取任务等。</description>
	</property>
	<property>
		<name>yarn.resourcemanager.admin.address.rm2</name>
		<value>nn2.hadoop:8033</value>
		<description>ResourceManager 对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等</description>
	</property>
	
	<property>
		<name>yarn.app.mapreduce.am.staging-dir</name>
		<value>/user</value>
	</property>
	 <property>
	 	<name>yarn.web-proxy.address</name>  
		<value>nn1.hadoop:8041</value>  
	</property>	
	<!--	scheduler begin	-->
        <property>
        	<name>yarn.scheduler.minimum-allocation-vcores</name>
        	<value>1</value>
        	<description>单个任务可申请的最小虚拟CPU个数</description>
        </property>
	
	<property>
		<name>yarn.scheduler.maximum-allocation-vcores</name>
		<value>36</value>
		<description>单个任务可申请的最大虚拟CPU个数，此参数对应yarn.nodemanager.resource.cpu-vcores，建议最大为一个物理CPU的数量</description>
	</property>
	
	<property>
		<name>yarn.scheduler.maximum-allocation-mb</name>
		<value>30720</value>
		<description>单个任务可申请的最多物理内存量</description>
	</property>
	
	<property>
		<name>yarn.resourcemanager.scheduler.class</name>
		<value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
		<description>调度器实现类</description>
	</property>

	<property>
		<name>yarn.scheduler.fair.allocation.file</name>
		<value>fair-scheduler.xml</value>
		<description>自定义XML配置文件所在位置，该文件主要用于描述各个队列的属性，比如资源量、权重等</description>
	</property>
	
	<property>
		<name>yarn.scheduler.fair.user-as-default-queue</name>
		<value>true</value>
		<description>当应用程序未指定队列名时，是否指定用户名作为应用程序所在的队列名。如果设置为false或者未设置，所有未知队列的应用程序将被提交到default队列中，默认值为true</description>
	</property>
	
	<property>
		<name>yarn.scheduler.fair.preemption</name>
		<value>true</value>
		<description>是否支持抢占</description>
	</property>
	
	<property>
		<name>yarn.scheduler.fair.sizebasedweight</name>
		<value>false</value>
		<description>在一个队列内部分配资源时，默认情况下，采用公平轮询的方法将资源分配各各个应用程序，而该参数则提供了外一种资源分配方式：按照应用程序资源需求数目分配资源，即需求资源数量越多，分配的资源越多。默认情况下，该参数值为false</description>
	</property>
	
	<property>
		<name>yarn.scheduler.increment-allocation-mb</name>
		<value>256</value>
		<description>内存规整化单位，默认是1024，这意味着，如果一个Container请求资源是1.5GB，则将被调度器规整化为ceiling(1.5 GB / 1GB) * 1G=2GB</description>
	</property>
	
	<property>
		<name>yarn.scheduler.assignmultiple</name>
		<value>true</value>
		<description>是否启动批量分配功能。当一个节点出现大量资源时，可以一次分配完成，也可以多次分配完成。默认情况下，参数值为false</description>
	</property>
	
	<property>
		<name>yarn.scheduler.fair.max.assign</name>
		<value>10</value>
		<description>如果开启批量分配功能，可指定一次分配的container数目。默认情况下，该参数值为-1，表示不限制</description>
	</property>
	<property>
		<name>yarn.scheduler.fair.allow-undeclared-pools</name>
		<value>false</value>
		<description>如果提交的队列名不存在，Scheduler会自动创建一个该队列，默认开启</description>
	</property>

	<!--	scheduler end	-->

	<property>
		<name>yarn.nodemanager.webapp.address</name>
		<value>0.0.0.0:8042</value>
	</property>
	<property>
		<name>yarn.nodemanager.localizer.address</name>
		<value>0.0.0.0:8040</value>
	</property>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
		<description>NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序</description>
	</property>
	<property>
		<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
		<value>org.apache.hadoop.mapred.ShuffleHandler</value>
	</property>

	<property>
		<name>mapreduce.shuffle.port</name>
		<value>23080</value>
	</property>
	<!--目录相关 -->
	<property>
		<name>yarn.nodemanager.local-dirs</name>
		<value>/data1/yarn/local,/data2/yarn/local,/data3/yarn/local,/data4/yarn/local,/data5/yarn/local,/data6/yarn/local</value>
		<description>中间结果存放位置，存放执行Container所需的数据如可执行程序或jar包，配置文件等和运行过程中产生的临时数据</description>
	</property>
	<property>
		<name>yarn.nodemanager.log-dirs</name>
		<value>/home/hadoop/yarn/logs</value>
		<description>Container运行日志存放地址（可配置多个目录）</description>
	</property>
	<property>
		<name>yarn.log-aggregation-enable</name>
		<value>true</value>
		<description>是否启用日志聚集功能</description>
	</property>
	<property>
		<name>yarn.nodemanager.remote-app-log-dir</name>
		<value>/tmp/app-logs</value>
		<description>当应用程序运行结束后，日志被转移到的HDFS目录（启用日志聚集功能时有效）</description>
	</property>
	<property>
		<name>yarn.log-aggregation.retain-seconds</name>
		<value>1209600</value>
		<description>nodemanager上所有Container的运行日志在HDFSZ中的保存时间，保留半个月</description>
	</property>
	
	<property>
		<name>yarn.nodemanager.address</name>
		<value>0.0.0.0:9103</value>
	</property>
	<property>
		<name>yarn.nodemanager.resource.memory-mb</name>
		<value>30720</value>
		<description>该节点上可分配的物理内存总量</description>
	</property>
	<property>
		<name>yarn.nodemanager.resource.cpu-vcores</name>
		<value>36</value>
		<description>该节点上YARN可使用的虚拟CPU个数，一个物理CPU对应3个虚拟CPU</description>
	</property>
	<property>
		<name>yarn.nodemanager.health-checker.script.path</name>
		<value>/usr/local/hadoop/etc/hadoop/health-check.sh</value>
		<description>健康状况检测脚本,脚本输出以“ERROR”开头的字符串，则认为节点处于不健康状态态</description>
	</property>
	<property>
		<name>yarn.nodemanager.vmem-check-enabled</name>
		<value>false</value>
		<description>虚拟内存检测，默认是True</description>
	</property>
	<property>
		<name>yarn.nodemanager.pmem-check-enabled</name>
		<value>false</value>
		<description>物理内存检测，默认是True</description>
	</property>
</configuration>
